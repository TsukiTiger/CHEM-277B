{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print('func:%r  took: %2.4f sec' % (f.__name__,  te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_chunks(complete_list, chunk_size=None, num_chunks=None):\n",
    "    '''\n",
    "    Cut a list into multiple chunks, each having chunk_size (the last chunk might be less than chunk_size) or having a total of num_chunk chunks\n",
    "    '''\n",
    "    chunks = []\n",
    "    if num_chunks is None:\n",
    "        num_chunks = math.ceil(len(complete_list) / chunk_size)\n",
    "    elif chunk_size is None:\n",
    "        chunk_size = math.ceil(len(complete_list) / num_chunks)\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(complete_list[i * chunk_size: (i + 1) * chunk_size])\n",
    "    return chunks\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, optimizer_type, learning_rate, epoch, batch_size, input_transform=lambda x: x,):\n",
    "        \"\"\" The class for training the model\n",
    "        model: nn.Module\n",
    "            A pytorch model\n",
    "        optimizer_type: 'adam' or 'sgd'\n",
    "        learning_rate: float\n",
    "        epoch: int\n",
    "        batch_size: int\n",
    "        input_transform: func\n",
    "            transforming input. Can do reshape here\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        if optimizer_type == \"sgd\":\n",
    "            self.optimizer = SGD(model.parameters(), learning_rate,momentum=0.9)\n",
    "        elif optimizer_type == \"adam\":\n",
    "            self.optimizer = ...\n",
    "            \n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.input_transform = input_transform\n",
    "\n",
    "\n",
    "    @timing\n",
    "    def train(self, inputs, outputs, val_inputs, val_outputs,early_stop=False,l2=False,silent=False):\n",
    "        \"\"\" train self.model with specified arguments\n",
    "        inputs: np.array, The shape of input_transform(input) should be (ndata,nfeatures)\n",
    "        outputs: np.array shape (ndata,)\n",
    "        val_nputs: np.array, The shape of input_transform(val_input) should be (ndata,nfeatures)\n",
    "        val_outputs: np.array shape (ndata,)\n",
    "        early_stop: bool\n",
    "        l2: bool\n",
    "        silent: bool. Controls whether or not to print the train and val error during training\n",
    "        \n",
    "        @return\n",
    "        a dictionary of arrays with train and val losses and accuracies\n",
    "        \"\"\"\n",
    "        ### convert data to tensor of correct shape and type here ###\n",
    "        ...\n",
    "        \n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        weights = self.model.state_dict()\n",
    "        lowest_val_loss = np.inf\n",
    "        \n",
    "        for n_epoch in tqdm(range(self.epoch), leave=False):\n",
    "            self.model.train()\n",
    "            batch_indices = list(range(inputs.shape[0]))\n",
    "            random.shuffle(batch_indices)\n",
    "            batch_indices = create_chunks(batch_indices, chunk_size=self.batch_size)\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for batch in batch_indices:\n",
    "                batch_importance = len(batch) / len(outputs)\n",
    "                batch_input = inputs[batch]\n",
    "                batch_output = outputs[batch]\n",
    "                ### make prediction and compute loss with loss function of your choice on this batch ###\n",
    "                batch_predictions = ...\n",
    "                loss = ...\n",
    "                if l2:\n",
    "                    ### Compute the loss with L2 regularization ###\n",
    "                    ...\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                ### Compute epoch_loss and epoch_acc\n",
    "                ...\n",
    "            val_loss, val_acc = self.evaluate(val_inputs, val_outputs, print_acc=False)\n",
    "            if n_epoch % 10 ==0 and not silent: \n",
    "                print(\"Epoch %d/%d - Loss: %.3f - Acc: %.3f\" % (n_epoch + 1, self.epoch, epoch_loss, epoch_acc))\n",
    "                print(\"              Val_loss: %.3f - Val_acc: %.3f\" % (val_loss, val_acc))\n",
    "            losses.append(epoch_loss)\n",
    "            accuracies.append(epoch_acc)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "            if early_stop:\n",
    "                if val_loss < lowest_val_loss:\n",
    "                    lowest_val_loss = val_loss\n",
    "                    weights = self.model.state_dict()\n",
    "\n",
    "        if early_stop:\n",
    "            self.model.load_state_dict(weights)    \n",
    "\n",
    "        return {\"losses\": losses, \"accuracies\": accuracies, \"val_losses\": val_losses, \"val_accuracies\": val_accuracies}\n",
    "        \n",
    "    def evaluate(self, inputs, outputs, print_acc=True):\n",
    "        \"\"\" evaluate model on provided input and output\n",
    "        inputs: np.array, The shape of input_transform(input) should be (ndata,nfeatures)\n",
    "        outputs: np.array shape (ndata,)\n",
    "        print_acc: bool\n",
    "        \n",
    "        @return\n",
    "        losses: float\n",
    "        acc: float\n",
    "        \"\"\"\n",
    "        ...\n",
    "        if print_acc:\n",
    "            print(\"Accuracy: %.3f\" % acc)\n",
    "        return losses, acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
